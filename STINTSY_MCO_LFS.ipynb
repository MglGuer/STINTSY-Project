{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1. Introduction ##\n",
    "\n",
    "In this notebook, the dataset to be processed is the Labor Force Survey conducted April 2016 and retrieved through Philippine Statistics Authority database. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import ScalarFormatter, FuncFormatter \n",
    "%matplotlib inline\n",
    " \n",
    "plt.rcParams['figure.figsize'] = (6.0, 6.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# autoreload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Importing LFS PUF April 2016.CSV</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "try:\n",
    "    lfs_data = pd.read_csv(\"LFS PUF April 2016.CSV\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: CSV file not found. Please make sure the file exists in the correct directory or provide the correct path.\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Information, Pre-Processing, and Cleaning</h1>\n",
    "\n",
    "Let's get an overview of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Of interest to us, there are:\n",
    "<ul><li>1 contains float values, </li>\n",
    "<li>14 contain integer values, and </li>\n",
    "<li><b>35 are object values</b>.</li></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check for duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs_data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No duplicates here, and therefore no cleaning need follow in this regard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset seems to contain null values in the form of whitespaces. Let's count those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_null = lfs_data.apply(lambda col: col.str.isspace().sum() if col.dtype == 'object' else 0)\n",
    "\n",
    "print(\"Number Empty Cells:\")\n",
    "print(has_null[has_null > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "And standardize, replacing these whitespace values with NaN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs_data.replace(r\"^\\s+$\", np.nan, regex=True, inplace=True)\n",
    "nan_counts_per_column = lfs_data.isna().sum()\n",
    "print(nan_counts_per_column[nan_counts_per_column > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Let's also apply the unique() function to our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs_data.apply(lambda x: x.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Considering our dataset has 18,000 entries, features with particularly low numbers stand out as questions that have clear, defined choices. Reviewing the [questionnaire](https://psada.psa.gov.ph/catalog/67/download/537), we find that certain questions ask the participant to specify beyond prespecified choices.\n",
    "\n",
    "This column possibly contains \"010,\" which is obviously not an integer. We ensure this column is a string, and check for values not specified in the questionnaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs_data['PUFC07_GRADE'] = lfs_data['PUFC07_GRADE'].astype(str)\n",
    "valid_codes = [\n",
    "    \"000\", \"010\",                                      # No Grade, Preschool\n",
    "    \"210\", \"220\", \"230\", \"240\", \"250\", \"260\", \"280\",  # Elementary\n",
    "    \"310\", \"320\", \"330\", \"340\", \"350\",                # High School\n",
    "    \"410\", \"420\",                                     # Post Secondary; If Graduate Specify\n",
    "    \"810\", \"820\", \"830\", \"840\",                       # College; If Graduate Specify\n",
    "    \"900\",                                            # Post Baccalaureate\n",
    "    \"nan\"\n",
    "]\n",
    "invalid_rows = lfs_data[~(lfs_data['PUFC07_GRADE'].isin(valid_codes))]\n",
    "\n",
    "unique_invalid_values = invalid_rows['PUFC07_GRADE'].unique()\n",
    "print(unique_invalid_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Values 5XX 6XX are not detailed in the questionnaire. As it instructs the participant to specify whether they graduated from post secondary or college, we'll create a new data point to encapsulate these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs_data.loc[~lfs_data['PUFC07_GRADE'].isin(valid_codes), 'PUFC07_GRADE'] = '700'\n",
    "print(lfs_data['PUFC07_GRADE'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = lfs_data.corr()\n",
    "\n",
    "plt.figure(figsize=(8, 6))  \n",
    "sns.heatmap(\n",
    "    corr_matrix,\n",
    "    annot=False,  \n",
    "    fmt=\".2f\",   \n",
    "    annot_kws={\"size\": 8}, \n",
    "    cmap='coolwarm',\n",
    "    cbar_kws={'shrink': 0.8} \n",
    ")\n",
    "plt.title(\"Correlation Matrix\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categorical_cols = ['PUFREG', 'PUFPRRCD', 'PUFC03_REL', 'PUFC23_PCLASS']\n",
    "for col in categorical_cols:\n",
    "    print(f\"Frequency distribution for {col}:\")\n",
    "    print(lfs_data[col].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lfs_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "fig, axes = plt.subplots(len(numerical_cols), 1, figsize=(10, 20))  \n",
    "\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    \n",
    "    data = lfs_data[col].dropna()\n",
    "\n",
    "    \n",
    "    if col == 'PUFC25_PBASIC' and data.min() > 0:\n",
    "        \n",
    "        sns.histplot(data, bins=30, kde=True, ax=axes[i], log_scale=True)\n",
    "\n",
    "        \n",
    "        axes[i].xaxis.set_major_formatter(ScalarFormatter())\n",
    "\n",
    "        \n",
    "        axes[i].xaxis.tick_top()\n",
    "        axes[i].xaxis.set_label_position('top')\n",
    "\n",
    "        \n",
    "        secax = axes[i].secondary_xaxis('bottom')\n",
    "\n",
    "        \n",
    "        tick_locations = [50, 125, 300, 700, 2000, 5000]\n",
    "        secax.set_xticks(tick_locations)\n",
    "        secax.set_xticklabels([f\"PhP{x:,}\" for x in tick_locations])\n",
    "\n",
    "        \n",
    "        secax.set_xlabel(\"Income (Philippine Pesos)\", labelpad=15)\n",
    "        axes[i].set_xlabel(\"Income (log scale)\", labelpad=15)\n",
    "\n",
    "    elif col == 'PUFC19_PHOURS':\n",
    "        \n",
    "        max_val = float(data.max())\n",
    "        sns.histplot(data, bins=np.arange(0, max_val+5, 5), kde=True, ax=axes[i])\n",
    "\n",
    "    else:\n",
    "        \n",
    "        sns.histplot(data, bins=20, kde=True, ax=axes[i])\n",
    "\n",
    "    axes[i].set_title(f\"Distribution of {col}\")\n",
    "    if col != 'PUFC25_PBASIC':\n",
    "        axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel(\"Frequency\")\n",
    "\n",
    "    \n",
    "    textstr = f'Mean: {data.mean():.2f}\\nMedian: {data.median():.2f}\\nStd: {data.std():.2f}'\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "    axes[i].text(0.05, 0.95, textstr, transform=axes[i].transAxes,\n",
    "                 verticalalignment='top', bbox=props)\n",
    "\n",
    "\n",
    "plt.tight_layout(h_pad=4.0)  \n",
    "plt.subplots_adjust(bottom=0.15)  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
