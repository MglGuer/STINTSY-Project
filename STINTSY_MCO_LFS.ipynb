{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1. Introduction ##\n",
    "\n",
    "In this notebook, the dataset to be processed is the Labor Force Survey conducted April 2016 and retrieved through Philippine Statistics Authority database. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (6.0, 6.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# autoreload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Importing LFS PUF April 2016.CSV</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "try:\n",
    "    lfs_data = pd.read_csv(\"LFS PUF April 2016.CSV\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: CSV file not found. Please make sure the file exists in the correct directory or provide the correct path.\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Information</h1>\n",
    "\n",
    "It is good practice to first obtain the <pre>info()</pre> of the dataset, in order to have a good preview of what to expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 180862 entries, 0 to 180861\n",
      "Data columns (total 50 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   PUFREG           180862 non-null  int64  \n",
      " 1   PUFPRV           180862 non-null  int64  \n",
      " 2   PUFPRRCD         180862 non-null  int64  \n",
      " 3   PUFHHNUM         180862 non-null  int64  \n",
      " 4   PUFURB2K10       180862 non-null  int64  \n",
      " 5   PUFPWGTFIN       180862 non-null  float64\n",
      " 6   PUFSVYMO         180862 non-null  int64  \n",
      " 7   PUFSVYYR         180862 non-null  int64  \n",
      " 8   PUFPSU           180862 non-null  int64  \n",
      " 9   PUFRPL           180862 non-null  int64  \n",
      " 10  PUFHHSIZE        180862 non-null  int64  \n",
      " 11  PUFC01_LNO       180862 non-null  int64  \n",
      " 12  PUFC03_REL       180862 non-null  int64  \n",
      " 13  PUFC04_SEX       180862 non-null  int64  \n",
      " 14  PUFC05_AGE       180862 non-null  int64  \n",
      " 15  PUFC06_MSTAT     180862 non-null  object \n",
      " 16  PUFC07_GRADE     180862 non-null  object \n",
      " 17  PUFC08_CURSCH    180862 non-null  object \n",
      " 18  PUFC09_GRADTECH  180862 non-null  object \n",
      " 19  PUFC10_CONWR     180862 non-null  object \n",
      " 20  PUFC11_WORK      180862 non-null  object \n",
      " 21  PUFC12_JOB       180862 non-null  object \n",
      " 22  PUFC14_PROCC     180862 non-null  object \n",
      " 23  PUFC16_PKB       180862 non-null  object \n",
      " 24  PUFC17_NATEM     180862 non-null  object \n",
      " 25  PUFC18_PNWHRS    180862 non-null  object \n",
      " 26  PUFC19_PHOURS    180862 non-null  object \n",
      " 27  PUFC20_PWMORE    180862 non-null  object \n",
      " 28  PUFC21_PLADDW    180862 non-null  object \n",
      " 29  PUFC22_PFWRK     180862 non-null  object \n",
      " 30  PUFC23_PCLASS    180862 non-null  object \n",
      " 31  PUFC24_PBASIS    180862 non-null  object \n",
      " 32  PUFC25_PBASIC    180862 non-null  object \n",
      " 33  PUFC26_OJOB      180862 non-null  object \n",
      " 34  PUFC27_NJOBS     180862 non-null  object \n",
      " 35  PUFC28_THOURS    180862 non-null  object \n",
      " 36  PUFC29_WWM48H    180862 non-null  object \n",
      " 37  PUFC30_LOOKW     180862 non-null  object \n",
      " 38  PUFC31_FLWRK     180862 non-null  object \n",
      " 39  PUFC32_JOBSM     180862 non-null  object \n",
      " 40  PUFC33_WEEKS     180862 non-null  object \n",
      " 41  PUFC34_WYNOT     180862 non-null  object \n",
      " 42  PUFC35_LTLOOKW   180862 non-null  object \n",
      " 43  PUFC36_AVAIL     180862 non-null  object \n",
      " 44  PUFC37_WILLING   180862 non-null  object \n",
      " 45  PUFC38_PREVJOB   180862 non-null  object \n",
      " 46  PUFC40_POCC      180862 non-null  object \n",
      " 47  PUFC41_WQTR      180862 non-null  object \n",
      " 48  PUFC43_QKB       180862 non-null  object \n",
      " 49  PUFNEWEMPSTAT    180862 non-null  object \n",
      "dtypes: float64(1), int64(14), object(35)\n",
      "memory usage: 69.0+ MB\n"
     ]
    }
   ],
   "source": [
    "lfs_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are 50 total variables/features in the dataset; of which, \n",
    "<ul><li>1 contains float values, </li>\n",
    "<li>14 contain integer values, and </li>\n",
    "<li><b>35 are object values</b>.</li></ul>\n",
    "<br>\n",
    "We can then infer that we must first <b>clean the 35 columns</b> that have object values before even doing any processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for further inspection, we have applied a <b>lambda function</b> onto each of the variables in the dataset. We have done this in order not to do the tedious work of using .unique() for every specified column, and instead applied it to all within LFS_Data. \n",
    "\n",
    "We can now <b>see all the unique values</b> present within <b>each variable/feature</b> within the dataset.\n",
    "\n",
    "We can see that for \"PUFC04_SEX\" or the Sex of the surveyed, there are only 2 unique entries;\n",
    "for \"PUFREG\" or the PH Region from where the survey was answered from, there are 17 unique entries;\n",
    "and for \"PUFHHNUM\" or the unique sequential number of the surveyed household, there are 40880 unique entries; etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PUFREG                17\n",
       "PUFPRV                86\n",
       "PUFPRRCD             116\n",
       "PUFHHNUM           40880\n",
       "PUFURB2K10             2\n",
       "PUFPWGTFIN         35599\n",
       "PUFSVYMO               1\n",
       "PUFSVYYR               1\n",
       "PUFPSU               975\n",
       "PUFRPL                 4\n",
       "PUFHHSIZE             20\n",
       "PUFC01_LNO            23\n",
       "PUFC03_REL            11\n",
       "PUFC04_SEX             2\n",
       "PUFC05_AGE           100\n",
       "PUFC06_MSTAT           7\n",
       "PUFC07_GRADE          68\n",
       "PUFC08_CURSCH          3\n",
       "PUFC09_GRADTECH        3\n",
       "PUFC10_CONWR           6\n",
       "PUFC11_WORK            3\n",
       "PUFC12_JOB             3\n",
       "PUFC14_PROCC          44\n",
       "PUFC16_PKB            88\n",
       "PUFC17_NATEM           4\n",
       "PUFC18_PNWHRS         17\n",
       "PUFC19_PHOURS        103\n",
       "PUFC20_PWMORE          3\n",
       "PUFC21_PLADDW          3\n",
       "PUFC22_PFWRK           3\n",
       "PUFC23_PCLASS          8\n",
       "PUFC24_PBASIS          9\n",
       "PUFC25_PBASIC       1152\n",
       "PUFC26_OJOB            3\n",
       "PUFC27_NJOBS           6\n",
       "PUFC28_THOURS        111\n",
       "PUFC29_WWM48H          6\n",
       "PUFC30_LOOKW           3\n",
       "PUFC31_FLWRK           3\n",
       "PUFC32_JOBSM           7\n",
       "PUFC33_WEEKS          36\n",
       "PUFC34_WYNOT          10\n",
       "PUFC35_LTLOOKW         4\n",
       "PUFC36_AVAIL           3\n",
       "PUFC37_WILLING         3\n",
       "PUFC38_PREVJOB         3\n",
       "PUFC40_POCC           44\n",
       "PUFC41_WQTR            3\n",
       "PUFC43_QKB            89\n",
       "PUFNEWEMPSTAT          4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfs_data.apply(lambda x: x.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IDK MIGHT BE UNNECESSARY TO SHOW, HELP\n",
    "\n",
    "-andrei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PUFREG</th>\n",
       "      <th>PUFPRV</th>\n",
       "      <th>PUFPRRCD</th>\n",
       "      <th>PUFHHNUM</th>\n",
       "      <th>PUFURB2K10</th>\n",
       "      <th>PUFPWGTFIN</th>\n",
       "      <th>PUFSVYMO</th>\n",
       "      <th>PUFSVYYR</th>\n",
       "      <th>PUFPSU</th>\n",
       "      <th>PUFRPL</th>\n",
       "      <th>PUFHHSIZE</th>\n",
       "      <th>PUFC01_LNO</th>\n",
       "      <th>PUFC03_REL</th>\n",
       "      <th>PUFC04_SEX</th>\n",
       "      <th>PUFC05_AGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>180862.000000</td>\n",
       "      <td>180862.000000</td>\n",
       "      <td>180862.000000</td>\n",
       "      <td>180862.000000</td>\n",
       "      <td>180862.000000</td>\n",
       "      <td>180862.000000</td>\n",
       "      <td>180862.0</td>\n",
       "      <td>180862.0</td>\n",
       "      <td>180862.000000</td>\n",
       "      <td>180862.000000</td>\n",
       "      <td>180862.000000</td>\n",
       "      <td>180862.000000</td>\n",
       "      <td>180862.000000</td>\n",
       "      <td>180862.000000</td>\n",
       "      <td>180862.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.398801</td>\n",
       "      <td>45.825309</td>\n",
       "      <td>4585.055324</td>\n",
       "      <td>20528.231873</td>\n",
       "      <td>1.574947</td>\n",
       "      <td>568.527169</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>386.270272</td>\n",
       "      <td>2.490379</td>\n",
       "      <td>5.504783</td>\n",
       "      <td>3.252391</td>\n",
       "      <td>2.931489</td>\n",
       "      <td>1.493874</td>\n",
       "      <td>27.889772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.667034</td>\n",
       "      <td>24.939767</td>\n",
       "      <td>2494.028733</td>\n",
       "      <td>11827.708144</td>\n",
       "      <td>0.494352</td>\n",
       "      <td>508.519331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>440.160045</td>\n",
       "      <td>1.118970</td>\n",
       "      <td>2.370169</td>\n",
       "      <td>2.077130</td>\n",
       "      <td>1.832299</td>\n",
       "      <td>0.499964</td>\n",
       "      <td>20.052132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34.998400</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2402.000000</td>\n",
       "      <td>10256.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>245.065975</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>20406.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>392.993500</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>7100.000000</td>\n",
       "      <td>30962.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>679.526775</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>482.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>9804.000000</td>\n",
       "      <td>40880.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4509.316000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>3053.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              PUFREG         PUFPRV       PUFPRRCD       PUFHHNUM  \\\n",
       "count  180862.000000  180862.000000  180862.000000  180862.000000   \n",
       "mean        9.398801      45.825309    4585.055324   20528.231873   \n",
       "std         4.667034      24.939767    2494.028733   11827.708144   \n",
       "min         1.000000       1.000000     100.000000       1.000000   \n",
       "25%         5.000000      24.000000    2402.000000   10256.250000   \n",
       "50%        10.000000      46.000000    4600.000000   20406.000000   \n",
       "75%        13.000000      71.000000    7100.000000   30962.000000   \n",
       "max        17.000000      98.000000    9804.000000   40880.000000   \n",
       "\n",
       "          PUFURB2K10     PUFPWGTFIN  PUFSVYMO  PUFSVYYR         PUFPSU  \\\n",
       "count  180862.000000  180862.000000  180862.0  180862.0  180862.000000   \n",
       "mean        1.574947     568.527169       4.0    2016.0     386.270272   \n",
       "std         0.494352     508.519331       0.0       0.0     440.160045   \n",
       "min         1.000000      34.998400       4.0    2016.0       1.000000   \n",
       "25%         1.000000     245.065975       4.0    2016.0     107.000000   \n",
       "50%         2.000000     392.993500       4.0    2016.0     243.000000   \n",
       "75%         2.000000     679.526775       4.0    2016.0     482.000000   \n",
       "max         2.000000    4509.316000       4.0    2016.0    3053.000000   \n",
       "\n",
       "              PUFRPL      PUFHHSIZE     PUFC01_LNO     PUFC03_REL  \\\n",
       "count  180862.000000  180862.000000  180862.000000  180862.000000   \n",
       "mean        2.490379       5.504783       3.252391       2.931489   \n",
       "std         1.118970       2.370169       2.077130       1.832299   \n",
       "min         1.000000       1.000000       1.000000       1.000000   \n",
       "25%         1.000000       4.000000       2.000000       2.000000   \n",
       "50%         2.000000       5.000000       3.000000       3.000000   \n",
       "75%         3.000000       7.000000       4.000000       3.000000   \n",
       "max         4.000000      23.000000      23.000000      11.000000   \n",
       "\n",
       "          PUFC04_SEX     PUFC05_AGE  \n",
       "count  180862.000000  180862.000000  \n",
       "mean        1.493874      27.889772  \n",
       "std         0.499964      20.052132  \n",
       "min         1.000000       0.000000  \n",
       "25%         1.000000      11.000000  \n",
       "50%         1.000000      24.000000  \n",
       "75%         2.000000      42.000000  \n",
       "max         2.000000      99.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfs_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is good practice to check the dataset for duplicate entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfs_data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing as there are no duplicate entries, this is good news for this dataset!\n",
    "\n",
    "Before we proceed to processing the data from this dataset, we first want to process all the Object datatypes in the 35 columns.\n",
    "\n",
    "It is also good practice to check if the Object datatype is caused by incorrect entries for the null value. \n",
    "\n",
    "We can check this by using the functions isnull() in tandem with any() in order to find all null values in each of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PUFREG             False\n",
       "PUFPRV             False\n",
       "PUFPRRCD           False\n",
       "PUFHHNUM           False\n",
       "PUFURB2K10         False\n",
       "PUFPWGTFIN         False\n",
       "PUFSVYMO           False\n",
       "PUFSVYYR           False\n",
       "PUFPSU             False\n",
       "PUFRPL             False\n",
       "PUFHHSIZE          False\n",
       "PUFC01_LNO         False\n",
       "PUFC03_REL         False\n",
       "PUFC04_SEX         False\n",
       "PUFC05_AGE         False\n",
       "PUFC06_MSTAT       False\n",
       "PUFC07_GRADE       False\n",
       "PUFC08_CURSCH      False\n",
       "PUFC09_GRADTECH    False\n",
       "PUFC10_CONWR       False\n",
       "PUFC11_WORK        False\n",
       "PUFC12_JOB         False\n",
       "PUFC14_PROCC       False\n",
       "PUFC16_PKB         False\n",
       "PUFC17_NATEM       False\n",
       "PUFC18_PNWHRS      False\n",
       "PUFC19_PHOURS      False\n",
       "PUFC20_PWMORE      False\n",
       "PUFC21_PLADDW      False\n",
       "PUFC22_PFWRK       False\n",
       "PUFC23_PCLASS      False\n",
       "PUFC24_PBASIS      False\n",
       "PUFC25_PBASIC      False\n",
       "PUFC26_OJOB        False\n",
       "PUFC27_NJOBS       False\n",
       "PUFC28_THOURS      False\n",
       "PUFC29_WWM48H      False\n",
       "PUFC30_LOOKW       False\n",
       "PUFC31_FLWRK       False\n",
       "PUFC32_JOBSM       False\n",
       "PUFC33_WEEKS       False\n",
       "PUFC34_WYNOT       False\n",
       "PUFC35_LTLOOKW     False\n",
       "PUFC36_AVAIL       False\n",
       "PUFC37_WILLING     False\n",
       "PUFC38_PREVJOB     False\n",
       "PUFC40_POCC        False\n",
       "PUFC41_WQTR        False\n",
       "PUFC43_QKB         False\n",
       "PUFNEWEMPSTAT      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfs_data.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing how all of the features returned a false value should be a happy sight to see!\n",
    "\n",
    "However, we must not be overconfident and too complacent.\n",
    "\n",
    "Upon actual inspection of the dataset through CSV file, we can see that there truly is an error in the returned FALSE values: there exists many empty entries per row.\n",
    "\n",
    "This means that the dataset does, in fact, have null values; just not in the form the computer recognizes as null. Instead, they are written in different variations of whitespace.\n",
    "\n",
    "Below actually finds all variations of null and counts how many null/blank instances there truly exists per column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Count of Missing Values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PUFREG                  0\n",
       "PUFPRV                  0\n",
       "PUFPRRCD                0\n",
       "PUFHHNUM                0\n",
       "PUFURB2K10              0\n",
       "PUFPWGTFIN              0\n",
       "PUFSVYMO                0\n",
       "PUFSVYYR                0\n",
       "PUFPSU                  0\n",
       "PUFRPL                  0\n",
       "PUFHHSIZE               0\n",
       "PUFC01_LNO              0\n",
       "PUFC03_REL              0\n",
       "PUFC04_SEX              0\n",
       "PUFC05_AGE              0\n",
       "PUFC06_MSTAT        18339\n",
       "PUFC07_GRADE        18339\n",
       "PUFC08_CURSCH      107137\n",
       "PUFC09_GRADTECH     57782\n",
       "PUFC10_CONWR        57782\n",
       "PUFC11_WORK         21894\n",
       "PUFC12_JOB          93306\n",
       "PUFC14_PROCC       108360\n",
       "PUFC16_PKB         108360\n",
       "PUFC17_NATEM       109507\n",
       "PUFC18_PNWHRS      109507\n",
       "PUFC19_PHOURS      109507\n",
       "PUFC20_PWMORE      109507\n",
       "PUFC21_PLADDW      109507\n",
       "PUFC22_PFWRK       109507\n",
       "PUFC23_PCLASS      109507\n",
       "PUFC24_PBASIS      138947\n",
       "PUFC25_PBASIC      144274\n",
       "PUFC26_OJOB        109507\n",
       "PUFC27_NJOBS       174924\n",
       "PUFC28_THOURS      109507\n",
       "PUFC29_WWM48H      163629\n",
       "PUFC30_LOOKW       132692\n",
       "PUFC31_FLWRK       178569\n",
       "PUFC32_JOBSM       178569\n",
       "PUFC33_WEEKS       178569\n",
       "PUFC34_WYNOT       134985\n",
       "PUFC35_LTLOOKW     179269\n",
       "PUFC36_AVAIL       174893\n",
       "PUFC37_WILLING     174893\n",
       "PUFC38_PREVJOB     132692\n",
       "PUFC40_POCC        152982\n",
       "PUFC41_WQTR         81627\n",
       "PUFC43_QKB         107825\n",
       "PUFNEWEMPSTAT       61337\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Actual Count of Missing Values\")\n",
    "white_fucking_spaces = [\" \" , \"  \" , \"   \" , \"     \"]\n",
    "lfs_data.isin(white_fucking_spaces).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for additional information, we can also take the total number of columns with null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Count of Columns with Missing Values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.int64(35)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Total Count of Columns with Missing Values\")\n",
    "(lfs_data.isin(white_fucking_spaces).sum() > 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have the following information:\n",
    "\n",
    "<ul><li>There are 35 columns that have the Object datatype</li>\n",
    "<li>Those 35 contain null values, hence incorrectly displaying the datatypes</li>\n",
    "<li>There exists columns with missing entries; ranging from 10.13% to 99.11% missing data per column</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    2\n",
       "2    1\n",
       "3    2\n",
       "4    2\n",
       "Name: PUFC06_MSTAT, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfs_data['PUFC06_MSTAT'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_fucking_spaces = [\" \" , \"  \" , \"   \" , \"     \"]\n",
    "df.isin(white_fucking_spaces).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Preprocessing and Data Cleaning</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace all instances of one or more spaces with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lfs_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mlfs_data\u001b[49m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m^\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms+$\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mnan, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lfs_data' is not defined"
     ]
    }
   ],
   "source": [
    "lfs_data.replace(r\"^\\s+$\", np.nan, regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>PUFC06_MSTAT</h2>\n",
    "Predictors:\n",
    "<ul><li>PUFC05_AGE</li>\n",
    "<li>PUFC04_SEX </li>\n",
    "<li>PUFC03_REL </li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "columns = [\"PUFC06_MSTAT\", \"PUFC05_AGE\", \"PUFC04_SEX\", \"PUFC03_REL\"]\n",
    "lfs_data_PUFC06_MSTAT = lfs_data[columns]\n",
    "pd.get_dummies(lfs_data_PUFC06_MSTAT, columns=[\"PUFC04_SEX\", \"PUFC03_REL\"])\n",
    "\n",
    "imputer = IterativeImputer(random_state=42)\n",
    "# lfs_data_PUFC06_MSTAT = pd.DataFrame(imputer.fit_transform(lfs_data_PUFC06_MSTAT), columns=lfs_data_PUFC06_MSTAT.columns)\n",
    "# lfs_data_PUFC06_MSTAT[\"PUFC06_MSTAT\"].round().astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ' '",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_51588\\2887404352.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlfs_data_PUFC06_MSTAT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimputer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlfs_data_PUFC06_MSTAT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlfs_data_PUFC06_MSTAT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m         \u001b[0mdata_to_wrap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m             return_tuple = (\n",
      "\u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1385\u001b[0m                 skip_parameter_validation=(\n\u001b[0;32m   1386\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1387\u001b[0m                 \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1388\u001b[0m             \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1389\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\impute\\_iterative.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    797\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimputation_sequence_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitial_imputer_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 801\u001b[1;33m         X, Xt, mask_missing_values, complete_mask = self._initial_imputation(\n\u001b[0m\u001b[0;32m    802\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_fit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\impute\\_iterative.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, in_fit)\u001b[0m\n\u001b[0;32m    623\u001b[0m             \u001b[0mensure_all_finite\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"allow-nan\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m             \u001b[0mensure_all_finite\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m         X = validate_data(\n\u001b[0m\u001b[0;32m    628\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2940\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2941\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2942\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2944\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"X\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2945\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2946\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2947\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1052\u001b[0m                         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m                 raise ValueError(\n\u001b[0;32m   1058\u001b[0m                     \u001b[1;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m                 \u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    835\u001b[0m         \u001b[1;31m# Use NumPy API to support order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    836\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    838\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 839\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    841\u001b[0m         \u001b[1;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m         \u001b[1;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m   2149\u001b[0m     def __array__(\n\u001b[0;32m   2150\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2151\u001b[0m     \u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2153\u001b[1;33m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2154\u001b[0m         if (\n\u001b[0;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2156\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: ' '"
     ]
    }
   ],
   "source": [
    "lfs_data_PUFC06_MSTAT = pd.DataFrame(imputer.fit_transform(lfs_data_PUFC06_MSTAT), columns=lfs_data_PUFC06_MSTAT.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs_data_PUFC06_MSTAT[\"PUFC06_MSTAT\"].round().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>PUFC08_CURSCH</h2>\n",
    "Is the person currently attending school?\n",
    "\n",
    "TODO: \n",
    "since current variables are just 1 and 2<br>\n",
    "where 1 or 2 represent \"elementary education\" and \"secondary and tertiary education\" accomplishment<br>\n",
    "<br>\n",
    "and so we will replace all null values with 0<br>\n",
    "to represent having NOT finished elementary, secondary, or tertiary.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PUFC31_FLWRK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PUFC32_JOBSM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PUFC33_WEEKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PUFC35_LTLOOKW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PUFC36_AVAIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PUFC37_WILLING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>One Hot Encoding</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idk pa what columns to hot encoding \n",
    "# df = pd.get_dummies(df, drop_first=True)  # One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Feature Selection</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idk pa rin what to do here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary \n",
    "\n",
    "TODO:<br>\n",
    "convert the columns that can be classified in a binary manner to 1s and 0s<br>\n",
    "ie. employment status: instead of \"employed\" and \"unemployed\"<br>\n",
    "convert to 1 and 0<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>kNN</h1>\n",
    "\n",
    "Employability or Job Prediction (kNN) (??)\n",
    "\n",
    "Rural vs Urban Workforce Disparities (kNN)\n",
    "<ul><li>group up regions that have similar labor market characteristics, challenges, and/or opportunities</li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: CSV file not found. Please make sure the file exists in the correct directory or provide the correct path.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'lfs_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 21\u001b[0m\n\u001b[0;32m     13\u001b[0m     exit()  \u001b[38;5;66;03m# Or another appropriate error handling\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# 2. Data Cleaning and Preprocessing (Crucial for kNN)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# --- A. Handle Missing Values ---\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# kNN is sensitive to missing values.  You'll need to decide how to handle them.  Common options:\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Option 1: Drop rows with any missing values (if the number of missing values is small)\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[43mlfs_data\u001b[49m\u001b[38;5;241m.\u001b[39mdropna(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# This modifies the DataFrame in place\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Option 2: Impute missing values (more common and often better)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m#   - Numerical features: Use mean, median, or more advanced imputation (e.g., KNN imputation)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m#     Example using median:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Identify your target variable (the one you want to predict) and features (the ones you'll use for prediction).\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Example (replace 'TARGET_COLUMN' and 'FEATURE_COLUMNS' with your actual column names):\u001b[39;00m\n\u001b[0;32m     37\u001b[0m TARGET_COLUMN \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmploymentStatus\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# Example - replace with your actual target variable\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lfs_data' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 1. Import the CSV file using pandas\n",
    "try:\n",
    "    lfs_data = pd.read_csv(\"LFS_PUF_April_2016.CSV\")  # Replace with the actual file name/path\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: CSV file not found. Please make sure the file exists in the correct directory or provide the correct path.\")\n",
    "    # Handle the error gracefully, e.g., exit the program or prompt the user for the correct path.\n",
    "    exit()  # Or another appropriate error handling\n",
    "\n",
    "# 2. Data Cleaning and Preprocessing (Crucial for kNN)\n",
    "\n",
    "# --- A. Handle Missing Values ---\n",
    "# kNN is sensitive to missing values.  You'll need to decide how to handle them.  Common options:\n",
    "\n",
    "# Option 1: Drop rows with any missing values (if the number of missing values is small)\n",
    "lfs_data.dropna(inplace=True)  # This modifies the DataFrame in place\n",
    "\n",
    "# Option 2: Impute missing values (more common and often better)\n",
    "#   - Numerical features: Use mean, median, or more advanced imputation (e.g., KNN imputation)\n",
    "#     Example using median:\n",
    "#     for col in lfs_data.select_dtypes(include=['number']).columns:\n",
    "#         lfs_data[col].fillna(lfs_data[col].median(), inplace=True)\n",
    "\n",
    "#   - Categorical features: Use mode (most frequent value)\n",
    "#     for col in lfs_data.select_dtypes(exclude=['number']).columns:\n",
    "#         lfs_data[col].fillna(lfs_data[col].mode()[0], inplace=True) # mode() returns a series, take the first element\n",
    "\n",
    "\n",
    "# --- B. Feature Selection/Engineering ---\n",
    "# Identify your target variable (the one you want to predict) and features (the ones you'll use for prediction).\n",
    "# Example (replace 'TARGET_COLUMN' and 'FEATURE_COLUMNS' with your actual column names):\n",
    "TARGET_COLUMN = 'EmploymentStatus' # Example - replace with your actual target variable\n",
    "FEATURE_COLUMNS = ['Age', 'EducationLevel', 'Occupation'] # Example - replace with your feature columns\n",
    "\n",
    "y = lfs_data[TARGET_COLUMN]  # Target variable\n",
    "X = lfs_data[FEATURE_COLUMNS] # Features\n",
    "\n",
    "# --- C. Encode Categorical Features ---\n",
    "# kNN works with numerical data. Convert categorical features to numerical using one-hot encoding or label encoding.\n",
    "\n",
    "X = pd.get_dummies(X) # One-hot encoding (often preferred for kNN)\n",
    "# OR\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# le = LabelEncoder()\n",
    "# for col in X.select_dtypes(exclude=['number']).columns:\n",
    "#     X[col] = le.fit_transform(X[col])\n",
    "\n",
    "# --- D. Feature Scaling (Very Important for kNN) ---\n",
    "# kNN is distance-based, so features with larger values can dominate. Scale your features.\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X) # Fit and transform the features\n",
    "\n",
    "# 3. Split Data into Training and Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)  # 80% train, 20% test\n",
    "\n",
    "# 4. Train the kNN Classifier\n",
    "k = 5  # Choose an appropriate value for k (number of neighbors) - often needs tuning\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# 5. Make Predictions\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# 6. Evaluate the Model\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "# --- Important Notes ---\n",
    "\n",
    "# * **File Path:** Double-check the path to your CSV file.  If it's not in the same directory as your notebook, provide the full path.\n",
    "# * **Data Exploration:** Before preprocessing, explore your data: `lfs_data.head()`, `lfs_data.info()`, `lfs_data.describe()`. This will help you understand the data types, missing values, and potential issues.\n",
    "# * **Feature Engineering:**  The choice of features and how you engineer them is *crucial* for model performance.\n",
    "# * **k Value Tuning:** Experiment with different values of `k` to find the optimal one. You can use techniques like cross-validation.\n",
    "# * **Handling Imbalanced Datasets:** If your target variable has imbalanced classes (e.g., many more examples of one class than another), consider techniques like oversampling or undersampling.\n",
    "# * **Computational Resources:** The LFS PUF is a large dataset. Be mindful of your computer's memory.  You might need to process the data in chunks if you run into memory issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression\n",
    "\n",
    "Employability (Binary Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "model = SGDClassifier(\n",
    "    loss='log_loss',\n",
    "    eta0=0.001,\n",
    "    max_iter=200,\n",
    "    learning_rate='constant',\n",
    "    random_state=1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>try</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Load the data\n",
    "try:\n",
    "    lfs_data = pd.read_csv(\"LFS PUF April 2016.CSV\")\n",
    "    print(\"Data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: CSV file not found. Please ensure the file is in the correct directory or provide the correct path.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PUFREG             0\n",
      "PUFPRV             0\n",
      "PUFPRRCD           0\n",
      "PUFHHNUM           0\n",
      "PUFURB2K10         0\n",
      "PUFPWGTFIN         0\n",
      "PUFSVYMO           0\n",
      "PUFSVYYR           0\n",
      "PUFPSU             0\n",
      "PUFRPL             0\n",
      "PUFHHSIZE          0\n",
      "PUFC01_LNO         0\n",
      "PUFC03_REL         0\n",
      "PUFC04_SEX         0\n",
      "PUFC05_AGE         0\n",
      "PUFC06_MSTAT       0\n",
      "PUFC07_GRADE       0\n",
      "PUFC08_CURSCH      0\n",
      "PUFC09_GRADTECH    0\n",
      "PUFC10_CONWR       0\n",
      "PUFC11_WORK        0\n",
      "PUFC12_JOB         0\n",
      "PUFC14_PROCC       0\n",
      "PUFC16_PKB         0\n",
      "PUFC17_NATEM       0\n",
      "PUFC18_PNWHRS      0\n",
      "PUFC19_PHOURS      0\n",
      "PUFC20_PWMORE      0\n",
      "PUFC21_PLADDW      0\n",
      "PUFC22_PFWRK       0\n",
      "PUFC23_PCLASS      0\n",
      "PUFC24_PBASIS      0\n",
      "PUFC25_PBASIC      0\n",
      "PUFC26_OJOB        0\n",
      "PUFC27_NJOBS       0\n",
      "PUFC28_THOURS      0\n",
      "PUFC29_WWM48H      0\n",
      "PUFC30_LOOKW       0\n",
      "PUFC31_FLWRK       0\n",
      "PUFC32_JOBSM       0\n",
      "PUFC33_WEEKS       0\n",
      "PUFC34_WYNOT       0\n",
      "PUFC35_LTLOOKW     0\n",
      "PUFC36_AVAIL       0\n",
      "PUFC37_WILLING     0\n",
      "PUFC38_PREVJOB     0\n",
      "PUFC40_POCC        0\n",
      "PUFC41_WQTR        0\n",
      "PUFC43_QKB         0\n",
      "PUFNEWEMPSTAT      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 2. Data Cleaning and Preprocessing\n",
    "\n",
    "# a. Handle Missing Values (Important!)\n",
    "# Explore missing data:\n",
    "print(lfs_data.isnull().sum()) # Check for missing values in each column\n",
    "# Strategies for handling missing data (choose one or combine as appropriate):\n",
    "# 1. Drop rows with many missing values (if applicable).\n",
    "# 2. Impute missing numerical values (e.g., mean, median).\n",
    "# 3. Impute missing categorical values (e.g., mode, or create a \"missing\" category).\n",
    "# Example imputation (replace with more suitable strategy as needed):\n",
    "# lfs_data['PUFC25_PBASIC'].fillna(lfs_data['PUFC25_PBASIC'].median(), inplace=True) # Impute with median for basic pay\n",
    "# lfs_data['PUFC07_GRADE'].fillna(\"Unknown\", inplace=True) # Impute with \"Unknown\" for grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 72\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# i think we can drop PUFSVYMO Survey month, PUFSVYYR Survey year\u001b[39;00m\n\u001b[0;32m      3\u001b[0m renamed_fucking_columns \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPUFREG\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRegion\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPUFPRV\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProvince code\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPUFNEWEMPSTAT\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNew Employment Criteria\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     71\u001b[0m }\n\u001b[1;32m---> 72\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.max_columns\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     73\u001b[0m lfs_data\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39mrenamed_fucking_columns, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     75\u001b[0m lfs_data\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m50\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# i think we can drop PUFSVYMO Survey month, PUFSVYYR Survey year\n",
    "\n",
    "renamed_fucking_columns = {\n",
    "    'PUFREG': 'Region',\n",
    "    'PUFPRV' : 'Province code',\n",
    "    'PUFPRRCD' : 'Province recode',\n",
    "    'PUFHHNUM' : 'Household unique sequential number',\n",
    "    'PUFURB2K10' : 'Urban / Rural',\n",
    "    'PUFPWGTFIN' : 'Final weight',\n",
    "    'PUFSVYMO' : 'Survey month',\n",
    "    'PUFSVYYR' : 'Survey year',\n",
    "    'PUFPSU' : 'PSU number',\n",
    "    'PUFRPL' : 'Replicate',\n",
    "    'PUFHHSIZE' : 'Number of household members',\n",
    "    'PUFC01_LNO' : 'Line number used to identify each member of the household in the survey',\n",
    "    'PUFC03_REL' : 'Relationship of the person to the household head',\n",
    "    'PUFC04_SEX' : 'Sex of the person',\n",
    "    'PUFC05_AGE' : 'Age of the person since last birthday',\n",
    "    'PUFC06_MSTAT' : 'Marital status of the person since last birthday',\n",
    "    'PUFC07_GRADE' : 'Highest grade completed of the person',\n",
    "    'PUFC08_CURSCH' : 'Is the person currently attending school?',\n",
    "    'PUFC09_GRADTECH' : 'Is the person a graduate of a technical / vocational course?',\n",
    "    'PUFC10_CONWR' : 'Category of OFW',\n",
    "    'PUFC11_WORK' : 'Did the person do any work for at least one house during the past week?',\n",
    "    'PUFC12_JOB' : 'Although the person did not work last week, did the person have a job or business during the past week?',\n",
    "    'PUFC14_PROCC' : 'What is the primary occupation of the person during the past week?',\n",
    "    'PUFC16_PKB' : 'Kind of business or industry of the person',\n",
    "    'PUFC17_NATEM' : 'Nature of employment of the person.',\n",
    "        # This refers to the permanence or regularity or seasonality with which a particular work or job/business is being pursued.\n",
    "    'PUFC18_PNWHRS' : 'Normal working hours per day',\n",
    "        # Normal working hours worked per day is the usual or prescribed working hours of a person in his primary job/business, which is, considered a full day's work.\n",
    "    'PUFC19_PHOURS' : 'Total number of hours worked during the past week',\n",
    "        # The actual number of hours worked by a person in his primary job that he held during the past week or in his other job(s)/business if there are or if there is any.\n",
    "        # It includes the duration or the period the person was occupied in his work, including overtime, but excluding hours paid but not worked. \n",
    "        # For wage and salary earners, it includes time worked without compensation in connection with their occupations, \n",
    "        # such as the time a teacher spends at home preparing for the forthcoming lectures. \n",
    "        # For own account workers, it includes the time spent in the shop, business or office, even if no sale or transaction has taken place.\n",
    "    'PUFC20_PWMORE' : 'Do you want more hours of work during the past week?',\n",
    "    'PUFC21_PLADDW' : 'Did the person look for additional work during the past week?',\n",
    "    'PUFC22_PFWRK' : \"Was this the person's first time to do any work?\",\n",
    "        # This question determines whether a person is a “new entrant” to the labor force. \n",
    "        # A person is a new entrant if it is his first time to do any work.\n",
    "        # A person is considered to have worked only for the first time if he started working only during the current survey period.\n",
    "        # Current survey period refers to April 1 - 30 for this survey round\n",
    "    'PUFC23_PCLASS' : 'Class of worker for primary occupation',\n",
    "        # Class of worker is the relationship of the worker to the establishment where he works.\n",
    "    'PUFC24_PBASIS' : 'Basis of payment for primary occupation',\n",
    "    'PUFC25_PBASIC' : 'Basic pay per day for primary occupation',\n",
    "        # Basic pay is the pay for normal time, prior to deductions of social security contributions, withholding taxes, etc. \n",
    "        # It excludes allowances, bonuses, commissions, overtime pay, benefits in kind, etc. \n",
    "        # This is also called basic wage.\n",
    "    'PUFC26_OJOB' : 'Did the person have other job or business during the past week?',\n",
    "    'PUFC27_NJOBS' : 'Number of jobs the person had during the past week',\n",
    "    'PUFC28_THOURS' : 'Total number of hours worked by the person for all his jobs during the past week',\n",
    "    'PUFC29_WWM48H' : 'Main reason for not working more than 48 hours in the past week',\n",
    "    'PUFC30_LOOKW' : 'Did the person look for work or try to establish a business in the past week?',\n",
    "    'PUFC31_FLWRK' : \"Was it the person's first time looking for work or trying to establish a business?\",\n",
    "    'PUFC32_JOBSM' : 'Job search method',\n",
    "        # What has the person been doing to find work?\n",
    "    'PUFC33_WEEKS' : 'Number of weeks spent in looking for work',\n",
    "        # How many weeks has the person been looking for work?',\n",
    "    'PUFC34_WYNOT' : 'Reason for not looking for work Why did the person not look for work?',\n",
    "    'PUFC35_LTLOOKW' : 'When was the last time the person looked for work?',\n",
    "    'PUFC36_AVAIL' : 'Had opportunity for work existed last week or within two weeks, would the person have been available?',\n",
    "    'PUFC37_WILLING' : 'Is the person willing to take up work in the past week or within 2 weeks?',\n",
    "    'PUFC38_PREVJOB' : 'Has the person worked at any time before?',\n",
    "    'PUFC40_POCC' : 'What was the person’s last occupation?',\n",
    "    'PUFC41_WQTR' : 'Did the person work at all or had a job or business during the past quarter?',\n",
    "    'PUFC43_QKB' : 'Kind of business for the past quarter',\n",
    "    'PUFNEWEMPSTAT' : 'New Employment Criteria'\n",
    "}\n",
    "pd.set_option('display.max_columns', None)\n",
    "lfs_data.rename(columns=renamed_fucking_columns, inplace=True)\n",
    "\n",
    "lfs_data.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b. Feature Selection (Crucial for a good model)\n",
    "# Identify features relevant to employability.  Consider these factors:\n",
    "# * Demographic features (age, sex, marital status, education)\n",
    "# * Work experience (previous jobs, hours worked)\n",
    "# * Job search activity (looking for work, methods used)\n",
    "# * Availability and willingness to work\n",
    "# * Location (region, urban/rural)\n",
    "\n",
    "# Example: Select some potentially relevant features (you'll likely want to refine this):\n",
    "selected_features = ['PUFC05_AGE', 'PUFC04_SEX', 'PUFC07_GRADE', 'PUFC11_WORK', 'PUFC14_PROCC', 'PUFC17_NATEM', 'PUFC23_PCLASS', 'PUFC30_LOOKW', 'PUFC36_AVAIL', 'PUFC37_WILLING', 'PUFNEWEMPSTAT']  # Add more!\n",
    "lfs_data = lfs_data[selected_features]\n",
    "\n",
    "# c. Encode Categorical Variables\n",
    "# Logistic regression works with numerical data. Convert categorical features:\n",
    "lfs_data = pd.get_dummies(lfs_data, columns=['PUFC04_SEX', 'PUFC07_GRADE', 'PUFC11_WORK', 'PUFC14_PROCC', 'PUFC17_NATEM', 'PUFC23_PCLASS', 'PUFC30_LOOKW', 'PUFC36_AVAIL', 'PUFC37_WILLING']) # One-hot encoding\n",
    "\n",
    "# d. Define Target Variable (Employability)\n",
    "# You'll need to define what \"employable\" means in your context.\n",
    "# Example: If PUFNEWEMPSTAT indicates employment status, you might use it directly.\n",
    "# Or, you might create a new target variable based on a combination of factors.\n",
    "# Example (using PUFNEWEMPSTAT directly as a binary indicator - Adapt as needed):\n",
    "lfs_data['employable'] = lfs_data['PUFNEWEMPSTAT'].apply(lambda x: 1 if x in [1, 2, 3] else 0) # Example: 1 if employed, 0 if not.  Adjust based on your data.\n",
    "lfs_data.drop('PUFNEWEMPSTAT', axis=1, inplace=True) # Remove the original employment status column if you created a new 'employable' column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['employable'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 3. Model Training\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mlfs_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43memployable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Features\u001b[39;00m\n\u001b[0;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m lfs_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memployable\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Target variable\u001b[39;00m\n\u001b[0;32m      5\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)  \u001b[38;5;66;03m# Split data\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5446\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['employable'] not found in axis\""
     ]
    }
   ],
   "source": [
    "\n",
    "# 3. Model Training\n",
    "X = lfs_data.drop('employable', axis=1)  # Features\n",
    "y = lfs_data['employable']  # Target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # Split data\n",
    "\n",
    "model = LogisticRegression(max_iter=1000) # Increase max_iter if needed.\n",
    "model.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 4. Model Evaluation\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      4\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# 4. Model Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Feature Importance (Optional but helpful)\n",
    "# Logistic regression can provide some insight into feature importance (coefficients):\n",
    "coefficients = model.coef_[0]\n",
    "feature_importance = pd.DataFrame({'Feature': X.columns, 'Importance': coefficients})\n",
    "feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(feature_importance)\n",
    "\n",
    "\n",
    "# Suggestions for an Outstanding Model:\n",
    "\n",
    "# * Thorough Data Cleaning: Handle missing values strategically.  Don't just drop them blindly. Imputation is often better.\n",
    "# * Feature Engineering: Create new features from existing ones.  For example, combine education and work experience.\n",
    "# * Feature Selection: Carefully choose the most relevant features. Use domain knowledge, statistical tests, or feature selection techniques (e.g., recursive feature elimination).\n",
    "# * Model Selection: Don't be limited to logistic regression. Explore other models like Random Forest, Gradient Boosting, or Support Vector Machines.\n",
    "# * Hyperparameter Tuning: Optimize the model's parameters using techniques like GridSearchCV or RandomizedSearchCV.\n",
    "# * Cross-Validation: Use techniques like k-fold cross-validation to get a more robust estimate of model performance.\n",
    "# * Address Class Imbalance (if present): If your dataset has a significantly unequal number of \"employable\" and \"not employable\" individuals, consider techniques like oversampling or undersampling.\n",
    "# * Domain Expertise:  The most important thing! Work with people who understand the Philippine labor market. Their insights will be invaluable for feature selection, defining \"employability,\" and interpreting the model's results.\n",
    "# * Explainability: Consider using techniques to make your model more interpretable. This is important for understanding why the model is making certain predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
