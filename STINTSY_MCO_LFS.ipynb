{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Introduction\n",
    "\n",
    "This notebook analyzes the Labor Force Survey (LFS) dataset from April 2016, provided by the Philippine Statistics Authority (PSA). The primary objective is to preprocess and clean the data, perform exploratory data analysis (EDA) to uncover insights, and build several machine learning models to predict whether an individual has worked in the past week. We will explore Logistic Regression, Decision Tree, and k-Nearest Neighbors models, tune their hyperparameters, and compare their performance to identify the most effective approach for this classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Imports and Setup\n",
    "\n",
    "First, we import the necessary Python libraries for data manipulation, visualization, and machine learning. We also configure default plotting styles and sizes for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "%matplotlib inline\n",
    "\n",
    "# Set default size of plots\n",
    "plt.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Autoreload external python modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Data Loading and Initial Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    lfs_data = pd.read_csv(\"src/data/LFS PUF April 2016.CSV\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: CSV file not found. Please make sure the file exists in the correct directory or provide the correct path.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Information, Pre-Processing, and Cleaning\n",
    "\n",
    "Let's start by getting a high-level overview of our dataset's structure, including the number of entries, column names, and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial output shows a mix of data types:\n",
    "<ul>\n",
    "    <li>1 column with float values.</li>\n",
    "    <li>14 columns with integer values.</li>\n",
    "    <li><b>35 columns with object (string) values</b>, which will likely require cleaning and conversion.</li>\n",
    "</ul>\n",
    "\n",
    "Next, we'll check for any duplicate rows in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs_data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No duplicates were found, so no action is needed in this regard.\n",
    "\n",
    "### Handling Whitespace and Null Values\n",
    "\n",
    "A common issue in datasets is the use of whitespace to represent missing or null values. Let's count the number of whitespace entries in our object-type columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_null = lfs_data.apply(lambda col: col.str.isspace().sum() if col.dtype == 'object' else 0)\n",
    "\n",
    "print(\"Columns with Empty Cells:\")\n",
    "print(has_null[has_null > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many columns contain a significant number of whitespace entries. Our strategy will be to handle these on a case-by-case basis. Instead of a blanket conversion to `NaN`, we will analyze each column to determine the most appropriate way to impute or re-categorize these missing values based on the survey's structure.\n",
    "\n",
    "We will now go through several key columns, cleaning them and converting their data types to be suitable for analysis and modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `PUFC06_MSTAT`: Marital Status\n",
    "\n",
    "This column represents the marital status of the respondent. Let's examine its current data type and unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data Type of PUFC06_MSTAT: \", lfs_data['PUFC06_MSTAT'].dtype)\n",
    "print(\"Values Used in PUFC06_MSTAT: \", sorted(lfs_data['PUFC06_MSTAT'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column is of type `object` and contains whitespace values. We will first replace the whitespace with an arbitrary integer (`-1`) to facilitate type conversion, and then cast the entire column to `int64`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs_data.loc[lfs_data['PUFC06_MSTAT'] == \" \", 'PUFC06_MSTAT'] = -1\n",
    "lfs_data['PUFC06_MSTAT'] = lfs_data['PUFC06_MSTAT'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon reviewing the LFS questionnaire documentation, it's clear that there is a specific code for \"unknown\" marital status. We can logically impute our missing values to this category, which corresponds to the integer `6`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs_data.loc[lfs_data['PUFC06_MSTAT'] == -1, 'PUFC06_MSTAT'] = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's double-check our work to ensure the column is now clean and has the correct data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data Type of PUFC06_MSTAT: \", lfs_data['PUFC06_MSTAT'].dtype)\n",
    "print(\"Values Used in PUFC06_MSTAT: \", np.sort(lfs_data['PUFC06_MSTAT'].unique().tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `PUFC07_GRADE`: Highest Grade Completed\n",
    "\n",
    "This column indicates the highest level of education attained by the respondent. We'll apply a similar cleaning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data Type of PUFC07_GRADE: \", lfs_data['PUFC07_GRADE'].dtype)\n",
    "print(\"Values Used in PUFC07_GRADE: \\n\", np.sort(lfs_data['PUFC07_GRADE'].unique().tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This column also contains whitespace and consists of numeric codes stored as strings. We will convert the whitespace to `-1` and cast the column to `int64`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs_data.loc[lfs_data['PUFC07_GRADE'] == \"   \", 'PUFC07_GRADE'] = -1\n",
    "lfs_data['PUFC07_GRADE'] = lfs_data['PUFC07_GRADE'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `-1` value now represents missing information about the highest grade completed. Let's verify the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data Type of PUFC07_GRADE: \", lfs_data['PUFC07_GRADE'].dtype)\n",
    "print(\"Values Used in PUFC07_GRADE: \\n\", np.sort(lfs_data['PUFC07_GRADE'].unique().tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cleaning, we can analyze the codes more deeply. By cross-referencing with the LFS questionnaire, we find that some numeric codes in our dataset are not explicitly defined in the manual. These likely represent specific courses for post-secondary and college graduates, which the survey allows respondents to specify.\n",
    "\n",
    "First, let's define the list of codes that *are* explicitly mentioned in the manual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the codes that were explicitly defined in the manual\n",
    "valid_codes = [ \n",
    "    0,                                                  # No Grade\n",
    "    10,                                                 # Preschool\n",
    "    210, 220, 230, 240, 250, 260, 280,                  # Elementary (Grade 1 to Elementary Graduate)\n",
    "    310, 320, 330, 340, 350,                            # High School (First Year to High School Graduate)\n",
    "    410, 420,                                           # Post Secondary; If Graduate Specify\n",
    "    810, 820, 830, 840,                                 # College; If Graduate Specify\n",
    "    900                                                 # Post Baccalaureate\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can identify the values present in our data that are not in this list of `valid_codes`. We hypothesize that these are the user-specified courses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_values = np.sort(lfs_data[~(lfs_data['PUFC07_GRADE'].isin(valid_codes))]['PUFC07_GRADE'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's separate our previously assigned missing value code (`-1`) from these other \"invalid\" codes, which we will now refer to as graduate-specified courses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = [-1]\n",
    "graduate_specified_courses = [int(x) for x in [value for value in invalid_values if value not in missing_values]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify this feature for modeling, we will group all of these specific graduate course codes into a single, new category. We will use the arbitrary code `700` for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs_data[\"PUFC07_GRADE\"] = lfs_data[\"PUFC07_GRADE\"].apply(lambda x: 700 if x in graduate_specified_courses else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print a summary of this preprocessing step to confirm our logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPUFC07_GRADE Data Type: \", lfs_data['PUFC07_GRADE'].dtype)\n",
    "print(\"\\nUnique Codes in Column: \", np.sort(lfs_data['PUFC07_GRADE'].unique().tolist()))\n",
    "print(\"\\nValid Codes (Original): \", valid_codes)\n",
    "print(\"\\nInvalid Codes Found (incl. missing): \", invalid_values)\n",
    "print(\"\\nAssigned Missing Code: \", missing_values)\n",
    "print(\"\\nCodes for Hypothesized Graduate Specified Courses: \", graduate_specified_courses)\n",
    "print(\"\\nArbitrary Code for Graduate Specified Courses: \", 700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `PUFC08_CURSCH`: Currently Attending School\n",
    "\n",
    "This column is a binary indicator of whether a person is currently in school."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data Type of PUFC08_CURSCH: \", lfs_data['PUFC08_CURSCH'].dtype)\n",
    "print(\"Values Used in PUFC08_CURSCH: \", sorted(lfs_data['PUFC08_CURSCH'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column has a large number of whitespace values. The questionnaire specifies that this question is only asked of respondents aged 5 to 24. We can therefore infer that individuals outside this age range did not answer, and it is logical to assume they are not currently attending school. We will map the whitespace values to `2` (No) and then convert the column to an integer type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs_data.loc[lfs_data['PUFC08_CURSCH'] == \" \", 'PUFC08_CURSCH'] = 2\n",
    "lfs_data['PUFC08_CURSCH'] = lfs_data['PUFC08_CURSCH'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the result of our conversion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data Type of PUFC08_CURSCH: \", lfs_data['PUFC08_CURSCH'].dtype)\n",
    "print(\"Values Used in PUFC08_CURSCH: \\n\", np.sort(lfs_data['PUFC08_CURSCH'].unique().tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `PUFC11_WORK`: Worked in the Past Week\n",
    "\n",
    "This is our target variable. It indicates if the person did any work for at least one hour during the past week. We'll clean it by mapping whitespace to `2` (No) and ensuring the data type is integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs_data.loc[lfs_data['PUFC11_WORK'] == \" \", 'PUFC11_WORK'] = 2\n",
    "lfs_data['PUFC11_WORK'] = lfs_data['PUFC11_WORK'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `PUFC30_LOOKW`: Looked for Work\n",
    "\n",
    "This column asks if the person looked for work in the past week. According to the survey's flow, this question is skipped (resulting in whitespace) if the respondent worked 48 hours or less. Therefore, a whitespace entry implies the person is not overworked and already has a job. We will handle this logic during preprocessing.\n",
    "\n",
    "First, we convert the column to a numeric format, using `-1` for the skipped entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Convert whitespace to -1 and other values to integers.\n",
    "lfs_data.loc[lfs_data['PUFC30_LOOKW'] == \" \", 'PUFC30_LOOKW'] = -1\n",
    "lfs_data.loc[lfs_data['PUFC30_LOOKW'] == \"1\", 'PUFC30_LOOKW'] = 1\n",
    "lfs_data.loc[lfs_data['PUFC30_LOOKW'] == \"2\", 'PUFC30_LOOKW'] = 2\n",
    "lfs_data['PUFC30_LOOKW'] = lfs_data['PUFC30_LOOKW'].astype('int64')\n",
    "\n",
    "# 2. For modeling purposes, create a second version of the column where skipped (-1) is treated as 'No' (2).\n",
    "# This simplifies the feature into a simple binary 'Yes'/'No' for looking for work.\n",
    "lfs_data['PUFC30_LOOKW_version2'] = lfs_data['PUFC30_LOOKW'].copy()\n",
    "lfs_data.loc[lfs_data['PUFC30_LOOKW_version2'] == -1, 'PUFC30_LOOKW_version2'] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original `PUFC30_LOOKW` column (with -1 for skipped) can be used to analyze overwork. A value of 1 or 2 indicates the person answered, which implies they worked more than 48 hours. A value of -1 (skipped) implies they worked 48 hours or less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_overworked_people = (lfs_data['PUFC30_LOOKW'] == -1).sum()\n",
    "overworked_people = (lfs_data['PUFC30_LOOKW'] == 1).sum() + (lfs_data['PUFC30_LOOKW'] == 2).sum()\n",
    "total_population = overworked_people + not_overworked_people\n",
    "\n",
    "print(f\"People who are NOT overworked (worked <= 48 hours): {not_overworked_people}\")\n",
    "print(f\"Percentage: {100 * not_overworked_people / total_population:.2f}%\")\n",
    "print(f\"\\nPeople who ARE overworked (worked > 48 hours): {overworked_people}\")\n",
    "print(f\"Percentage: {100 * overworked_people / total_population:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `PUFC31_FLWRK`: First Time Looking for Work\n",
    "\n",
    "This column is also part of a sequence of questions and will be cleaned similarly to the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Convert whitespace to -1 and other values to integers.\n",
    "lfs_data.loc[lfs_data['PUFC31_FLWRK'] == \" \", 'PUFC31_FLWRK'] = -1\n",
    "lfs_data.loc[lfs_data['PUFC31_FLWRK'] == \"1\", 'PUFC31_FLWRK'] = 1\n",
    "lfs_data.loc[lfs_data['PUFC31_FLWRK'] == \"2\", 'PUFC31_FLWRK'] = 2\n",
    "lfs_data['PUFC31_FLWRK'] = lfs_data['PUFC31_FLWRK'].astype('int64')\n",
    "\n",
    "# 2. Create a simplified binary version for modeling.\n",
    "lfs_data['PUFC31_FLWRK_version2'] = lfs_data['PUFC31_FLWRK'].copy()\n",
    "lfs_data.loc[lfs_data['PUFC31_FLWRK_version2'] == -1, 'PUFC31_FLWRK_version2'] = 2 # Treat skipped as 'No'\n",
    "\n",
    "print(\"Cleaned Data Type:\", lfs_data['PUFC31_FLWRK_version2'].dtype)\n",
    "print(\"Unique Values:\", lfs_data['PUFC31_FLWRK_version2'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `PUFC34_WYNOT`: Reason for Not Looking for Work\n",
    "\n",
    "This column provides reasons why a person might not be looking for work. We will clean it and create a version where skipped entries are mapped to a specific category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Convert all values to a consistent integer format.\n",
    "lfs_data.loc[lfs_data['PUFC34_WYNOT'] == \" \", 'PUFC34_WYNOT'] = -1\n",
    "lfs_data['PUFC34_WYNOT'] = pd.to_numeric(lfs_data['PUFC34_WYNOT'])\n",
    "lfs_data['PUFC34_WYNOT'] = lfs_data['PUFC34_WYNOT'].astype('int64')\n",
    "\n",
    "# 2. Create a version for modeling where skipped entries (-1) are mapped to category 9 ('Others specify').\n",
    "# This assumes that if a reason wasn't given, it falls into a general 'other' category or the question was not applicable.\n",
    "lfs_data['PUFC34_WYNOT_version3'] = lfs_data['PUFC34_WYNOT'].copy()\n",
    "lfs_data.loc[lfs_data['PUFC34_WYNOT_version3'] == -1, 'PUFC34_WYNOT_version3'] = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `PUFC38_PREVJOB`: Ever Worked Before\n",
    "\n",
    "This column asks if the respondent has any prior work experience. We will clean it using the same methodology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Convert to integer format, with -1 for whitespace.\n",
    "lfs_data.loc[lfs_data['PUFC38_PREVJOB'] == \" \", 'PUFC38_PREVJOB'] = -1\n",
    "lfs_data.loc[lfs_data['PUFC38_PREVJOB'] == \"1\", 'PUFC38_PREVJOB'] = 1\n",
    "lfs_data.loc[lfs_data['PUFC38_PREVJOB'] == \"2\", 'PUFC38_PREVJOB'] = 2\n",
    "lfs_data['PUFC38_PREVJOB'] = lfs_data['PUFC38_PREVJOB'].astype('int64')\n",
    "\n",
    "# 2. Create a simplified binary version where skipped is treated as 'No'.\n",
    "lfs_data['PUFC38_PREVJOB_version2'] = lfs_data['PUFC38_PREVJOB'].copy()\n",
    "lfs_data.loc[lfs_data['PUFC38_PREVJOB_version2'] == -1, 'PUFC38_PREVJOB_version2'] = 2\n",
    "\n",
    "print(lfs_data['PUFC38_PREVJOB_version2'].dtype)\n",
    "print(lfs_data['PUFC38_PREVJOB_version2'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalizing Data Type Conversion\n",
    "\n",
    "Now that we've handled the most complex columns, we can perform a broader conversion. We will replace all remaining whitespace across the dataframe with our placeholder `-1` and then attempt to convert all remaining object columns to integer type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs_data.replace(r\"^\\s+$\", -1, regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_convert = [\n",
    "    'PUFC09_GRADTECH', 'PUFC10_CONWR', \n",
    "    'PUFC12_JOB', 'PUFC14_PROCC', 'PUFC16_PKB', 'PUFC17_NATEM', 'PUFC18_PNWHRS', \n",
    "    'PUFC19_PHOURS', 'PUFC20_PWMORE', 'PUFC21_PLADDW', 'PUFC22_PFWRK', 'PUFC23_PCLASS', \n",
    "    'PUFC24_PBASIS', 'PUFC25_PBASIC', 'PUFC26_OJOB', 'PUFC27_NJOBS', 'PUFC28_THOURS', \n",
    "    'PUFC29_WWM48H', 'PUFC32_JOBSM', 'PUFC33_WEEKS', \n",
    "    'PUFC35_LTLOOKW', 'PUFC36_AVAIL', 'PUFC37_WILLING', \n",
    "    'PUFC40_POCC', 'PUFC41_WQTR', 'PUFC43_QKB', 'PUFNEWEMPSTAT'\n",
    "]\n",
    "\n",
    "for col in columns_to_convert:\n",
    "    if col in lfs_data.columns:\n",
    "        lfs_data[col] = lfs_data[col].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a final look at the number of unique values in each column after cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs_data.apply(lambda x: x.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Exploratory Data Analysis (EDA)\n",
    "\n",
    "With the data cleaned and preprocessed, we can now explore it to find patterns, correlations, and insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Analysis\n",
    "\n",
    "We'll start by computing a correlation matrix to identify strong linear relationships between our numeric variables. For this calculation, we'll temporarily replace our `-1` placeholder with `NaN` so that these values are ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs_data_with_nan = lfs_data.copy()\n",
    "lfs_data_with_nan.replace(-1, np.nan, inplace=True)\n",
    "corr_matrix = lfs_data_with_nan.corr()\n",
    "\n",
    "strong_correlations = []\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i + 1, len(corr_matrix.columns)): \n",
    "        corr_value = corr_matrix.iloc[i, j]\n",
    "        if (0.5 < corr_value < 1) or (-1 < corr_value < -0.5):\n",
    "            strong_correlations.append((\n",
    "                corr_matrix.index[i], \n",
    "                corr_matrix.columns[j], \n",
    "                corr_value\n",
    "            ))\n",
    "\n",
    "strong_correlations.sort(key=lambda x: abs(x[2]), reverse=True)\n",
    "\n",
    "print(\"Strong correlations (|corr| > 0.5):\")\n",
    "for var1, var2, corr in strong_correlations:\n",
    "    print(f\"{var1} — {var2}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Placeholder for Interpretation:** The output above lists pairs of variables with a correlation coefficient greater than 0.5 or less than -0.5. This helps us understand which variables move together. For example, a strong positive correlation between 'total hours worked' and 'income' would be expected. High correlations between predictor variables can also indicate multicollinearity, which might be a concern for some modeling techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations\n",
    "\n",
    "Now, we will create a series of plots to visualize the relationships between different demographic variables and occupation or work status."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Occupation Distribution by Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupation_sex = lfs_data.groupby(['PUFC04_SEX', 'PUFC14_PROCC']).size().unstack(fill_value=0)\n",
    "occupation_sex.plot(kind='bar', stacked=True, figsize=(12, 6))\n",
    "plt.title('Occupation Distribution by Sex')\n",
    "plt.xlabel('Sex')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks([0, 1], ['Male', 'Female'], rotation=0) # Assuming 1 is Male, 2 is Female or vice versa\n",
    "plt.legend(title='Occupation', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Placeholder for Interpretation:** This stacked bar chart shows the distribution of various occupations for males and females. It allows us to see which occupations are more prevalent for each gender and observe the overall workforce composition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Occupation Distribution by Marital Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupation_marriageStatus = lfs_data.groupby(['PUFC06_MSTAT', 'PUFC14_PROCC']).size().unstack(fill_value=0)\n",
    "occupation_marriageStatus.plot(kind='bar', stacked=True, figsize=(20, 10))\n",
    "plt.title('Occupation Distribution by Marital Status')\n",
    "plt.xlabel('Marital Status')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Occupation', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Placeholder for Interpretation:** This chart breaks down occupation types by the marital status of the respondents. We can analyze if certain occupations are more common among single, married, or widowed individuals, which might reflect different life stages and career paths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Occupation Distribution by Highest Grade Accomplished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupation_highestGrade = lfs_data.groupby(['PUFC07_GRADE', 'PUFC14_PROCC']).size().unstack(fill_value=0)\n",
    "occupation_highestGrade.plot(kind='bar', stacked=True, figsize=(20, 10))\n",
    "plt.title('Occupation Distribution by Highest Grade Accomplished')\n",
    "plt.xlabel('Highest Grade')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Occupation', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Placeholder for Interpretation:** This visualization explores the relationship between education level and occupation. It helps to illustrate how higher levels of education may lead to different types of employment, highlighting the value of education in the labor market."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relationship Between Looking for Work and Current Work Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupation_looking_for_work_ver2 = lfs_data.groupby(['PUFC30_LOOKW_version2', 'PUFC11_WORK']).size().unstack(fill_value=0)\n",
    "occupation_looking_for_work_ver2.plot(kind='bar', stacked=True, figsize=(12, 7))\n",
    "plt.title('Work Status vs. Looking for Work')\n",
    "plt.xlabel('Did the person look for work in the past week?')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks([0, 1], ['No', 'Yes'], rotation=0)\n",
    "plt.legend(title='Worked last week?', labels=['Yes', 'No'], bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "occupation_looking_for_work = lfs_data.groupby(['PUFC30_LOOKW', 'PUFC11_WORK']).size().unstack(fill_value=0)\n",
    "occupation_looking_for_work.plot(kind='bar', stacked=True, figsize=(12, 7))\n",
    "plt.title('Work Status vs. Looking for Work (with Skipped)')\n",
    "plt.xlabel('Did the person look for work in the past week?')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks([0, 1, 2], ['Skipped', 'Yes', 'No'], rotation=0)\n",
    "plt.legend(title='Worked last week?', labels=['Yes', 'No'], bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reasons for Not Looking for Work vs. Work Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupation_reason_not_looking_for_work_version3 = lfs_data.groupby(['PUFC34_WYNOT_version3', 'PUFC11_WORK']).size().unstack(fill_value=0)\n",
    "occupation_reason_not_looking_for_work_version3.plot(kind='bar', stacked=True, figsize=(20, 10))\n",
    "plt.title('Reasons for Not Looking for Work vs. Work Status')\n",
    "plt.xlabel(\"Reason for not looking for work\")\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(ticks=range(9), labels=[\n",
    "    'Tired/believed no work available', \n",
    "    'Awaiting results of previous job application', \n",
    "    'Temporary illness/disability', \n",
    "    'Bad weather', \n",
    "    'Waiting for rehire/job recall', \n",
    "    'Too young/old or retired/permanent disability', \n",
    "    'Household, family duties', \n",
    "    'Schooling', \n",
    "    'Others/Not Applicable'\n",
    "], rotation=45, ha='right')\n",
    "plt.legend(title='Worked last week?', labels=['Yes', 'No'], bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Predictive Modeling\n",
    "\n",
    "We will now build machine learning models to predict our target variable, `PUFC11_WORK` — whether a person has worked in the past week. We will test three different classification algorithms: Logistic Regression, Decision Tree, and k-Nearest Neighbors.\n",
    "\n",
    "### Feature Selection and Preprocessing for Modeling\n",
    "\n",
    "We select a set of demographic and economic features as our predictors. We will use a custom `prepare_data` function to handle the final steps of creating training and testing sets. Specifically, it will create five different 80/20 train-test splits (folds) to allow for robust evaluation. It will also perform one-hot encoding on our categorical features to convert them into a numerical format suitable for the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing import prepare_data_kfold\n",
    "\n",
    "target_col = 'PUFC11_WORK'\n",
    "feature_cols = [\n",
    "    'PUFC05_AGE', 'PUFC06_MSTAT', 'PUFC04_SEX', \n",
    "    'PUFC07_GRADE', 'PUFC08_CURSCH', \n",
    "    'PUFC38_PREVJOB', 'PUFC31_FLWRK',\n",
    "    'PUFC30_LOOKW', 'PUFC34_WYNOT'\n",
    "]\n",
    "\n",
    "categorical_cols = feature_cols\n",
    "n_splits = 5\n",
    "missing_value = -1\n",
    "seed = 45\n",
    "\n",
    "\n",
    "folds_data = prepare_data_kfold(lfs_data, target_col=target_col,\n",
    "                         missing_value=missing_value,\n",
    "                         feature_cols=feature_cols,\n",
    "                         seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Logistic Regression (LR)\n",
    "\n",
    "Logistic Regression is an excellent baseline model for binary classification. It is efficient, interpretable, and provides a good starting point for evaluating predictability.\n",
    "\n",
    "#### Training the Baseline LR Model\n",
    "We will train the model across our five folds using a set of initial hyperparameters. We'll use Stochastic Gradient Descent as the optimizer and monitor performance on both training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.trainEval import train_model\n",
    "\n",
    "result_dict = train_model(\n",
    "    folds_data,\n",
    "    scheduler_step_size=5,\n",
    "    learning_rate=0.01,\n",
    "    scheduler_gamma=0.5,\n",
    "    convergence_threshold=1e-4, \n",
    "    num_epochs=50,\n",
    "    patience=3, # Stop at 3 epochs with no improvement\n",
    "    weight_decay=0, # No regularization for the baseline\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "lr_accuracies_test = result_dict[\"all_final_test_accuracies\"]\n",
    "print(\"Test Accuracies per Fold:\", lr_accuracies_test);\n",
    "\n",
    "print(\"\\nModel training complete!\")\n",
    "aggregate_cm = result_dict[\"aggregate_confusion_matrix\"]\n",
    "\n",
    "sns.heatmap(aggregate_cm, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "            xticklabels=[\"Did not Work\", \"Worked\"], \n",
    "            yticklabels=[\"Did not Work\", \"Worked\"]) \n",
    "\n",
    "print(f\"\\n  Average Final Train Loss:     {result_dict['aggregated_final_metrics']['avg_final_train_loss']:.6f}\")\n",
    "print(f\"  Average Final Test Loss:      {result_dict['aggregated_final_metrics']['avg_final_test_loss']:.6f}\")\n",
    "print(f\"  Average Final Train Accuracy: {result_dict['aggregated_final_metrics']['avg_final_train_accuracy']:.6f}\")\n",
    "print(f\"  Average Final Test Accuracy:  {result_dict['aggregated_final_metrics']['avg_final_test_accuracy']:.6f}\")\n",
    "\n",
    "plt.title(\"Aggregate Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline LR Evaluation\n",
    "**Placeholder for Interpretation:** The output from the training process would show the average accuracy and loss across all five folds. The aggregate confusion matrix visualizes the model's performance, showing the counts of true positives, true negatives, false positives, and false negatives. A good baseline model will have high accuracy and a low number of misclassifications (off-diagonal elements in the matrix). The small difference between training and test metrics suggests the model is generalizing well without significant overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning: LR\n",
    "\n",
    "To improve our baseline, we will perform hyperparameter tuning using Randomized Search. This method efficiently samples a wide range of parameter combinations to find a more optimal set. We will search across learning rates, batch sizes, optimizers, and regularization strengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "    'learning_rate': np.logspace(-4, -1, 20),\n",
    "    'batch_size': [32, 64, 128, 256],\n",
    "    'optimizer': ['sgd', 'adam', 'rmsprop'],\n",
    "    'weight_decay': np.logspace(-5, -2, 10),\n",
    "    'num_epochs': [30, 50, 75, 100],\n",
    "    'scheduler_step_size': [5, 10, 15],\n",
    "    'scheduler_gamma': [0.5, 0.7, 0.9],\n",
    "    'patience': [3, 5, 7]\n",
    "}\n",
    "\n",
    "hyperparameter_results = hyperparameter_random_search(folds_data=folds_data, param_distributions=param_distributions, n_iter_search=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Decision Tree (DT)\n",
    "\n",
    "Decision Trees are powerful models that can capture non-linear relationships in the data. They work by recursively partitioning the data based on feature values, creating a tree-like structure of decision rules.\n",
    "\n",
    "#### Training the Baseline DT Model\n",
    "We will use the same one-hot encoded data from our folds to train a Decision Tree classifier. We'll set a `min_impurity_decrease` to provide some basic pre-pruning and prevent the tree from growing too complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, log_loss, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "\n",
    "accuracies_train = []\n",
    "losses_train = []\n",
    "dt_accuracies_test = []\n",
    "losses_test = []\n",
    "confusion_matrices = []\n",
    "\n",
    "for i in range(5):\n",
    "    X_train, X_test, y_train, y_test = (\n",
    "        folds_data[i]['X_train'],\n",
    "        folds_data[i]['X_test'],\n",
    "        folds_data[i]['y_train'],\n",
    "        folds_data[i]['y_test'],\n",
    "    )\n",
    "\n",
    "    model = DecisionTreeClassifier(random_state=45, min_impurity_decrease=0.001)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred_proba = model.predict_proba(X_train)\n",
    "    loss_train = log_loss(y_train, y_train_pred_proba)\n",
    "    accuracies_train.append(accuracy_score(y_train, model.predict(X_train)))\n",
    "    losses_train.append(loss_train)\n",
    "\n",
    "    y_test_pred_proba = model.predict_proba(X_test)\n",
    "    loss_test = log_loss(y_test, y_test_pred_proba)\n",
    "    dt_accuracies_test.append(accuracy_score(y_test, model.predict(X_test)))\n",
    "    losses_test.append(loss_test)\n",
    "\n",
    "    cm = confusion_matrix(y_test, model.predict(X_test))\n",
    "    confusion_matrices.append(cm)\n",
    "\n",
    "print(f\"Average Test Accuracy: {np.mean(dt_accuracies_test):.4f}\")\n",
    "print(f\"Average Test Loss: {np.mean(losses_test):.4f}\")\n",
    "print(\"\\nOverall Confusion Matrix:\")\n",
    "print(sum(confusion_matrices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline DT Evaluation\n",
    "**Placeholder for Interpretation:** The baseline Decision Tree model shows strong performance. The small gap between average training accuracy and test accuracy indicates that our initial pruning was effective in preventing significant overfitting. The overall confusion matrix would confirm the model's high predictive power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning: DT\n",
    "We will again use Randomized Search to find better hyperparameters for our Decision Tree. We will explore various criteria (`gini`, `entropy`), tree depth, sample requirements for splitting nodes, and both pre-pruning (`min_impurity_decrease`) and post-pruning (`ccp_alpha`) techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "p_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [30, 45, 50, 60],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"min_impurity_decrease\": [0.001, 0.005, 0.01], # pre-pruning\n",
    "    \"ccp_alpha\": np.logspace(-4, 0, 10) # post-pruning\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final DT Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sample = folds_data[0]['X_test'] # Using one fold's test set for final evaluation example\n",
    "y_test_sample = folds_data[0]['y_test']\n",
    "\n",
    "test_preds = best_model.predict(X_test_sample)\n",
    "test_acc = accuracy_score(y_test_sample, test_preds)\n",
    "test_loss = log_loss(y_test_sample, best_model.predict_proba(X_test_sample))\n",
    "\n",
    "print(f\"Final Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Final Test Log Loss: {test_loss:.4f}\")\n",
    "\n",
    "cm = confusion_matrix(y_test_sample, test_preds)  \n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix for Final DT Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: k-Nearest Neighbors (kNN)\n",
    "\n",
    "kNN is a simple, instance-based learning algorithm that classifies a data point based on the majority class of its 'k' nearest neighbors. It makes no assumptions about the underlying data distribution.\n",
    "\n",
    "#### Training the Baseline kNN Model\n",
    "We will start with a default `k` value of 5 and use distance weighting, meaning closer neighbors have more influence on the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial k value; an optimal value will be determined later.\n",
    "k = 5\n",
    "knn_accuracies_test = []\n",
    "\n",
    "for i, fold in enumerate(folds_data):\n",
    "    X_train, y_train = fold['X_train'], fold['y_train']\n",
    "    X_test, y_test = fold['X_test'], fold['y_test']\n",
    "\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
    "    knn_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = knn_model.predict(X_test)\n",
    "    accuracy_test = accuracy_score(y_test, y_pred)\n",
    "    knn_accuracies_test.append(accuracy_test)\n",
    "    print(f\"Fold {i+1} - Test Accuracy: {accuracy_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning: Finding the Optimal k\n",
    "The most critical hyperparameter for kNN is `k` itself. A small `k` can be sensitive to noise, while a large `k` can be computationally expensive and may oversmooth the decision boundary. We will use `GridSearchCV` to systematically test a range of `k` values and find the one that yields the best cross-validated accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_neighbors': range(1, 31)} \n",
    "\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(weights='distance'), param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train_full, y_train_full)\n",
    "\n",
    "print(\"Best k:\", grid_search.best_params_['n_neighbors'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Model Comparison and Conclusion\n",
    "\n",
    "Finally, we will compare the performance of our three tuned models: Logistic Regression, Decision Tree, and k-Nearest Neighbors. We will look at their test accuracies across the five folds to determine which model performed the best on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_accuracies_test = np.array(lr_accuracies_test)\n",
    "dt_accuracies_test = np.array(dt_accuracies_test)\n",
    "knn_accuracies_test = np.array(knn_accuracies_test)\n",
    "\n",
    "print(f\"Logistic Regression Average Test Accuracy: {np.mean(lr_accuracies_test):.4f} (+/- {np.std(lr_accuracies_test):.4f})\")\n",
    "print(f\"Decision Tree Average Test Accuracy:       {np.mean(dt_accuracies_test):.4f} (+/- {np.std(dt_accuracies_test):.4f})\")\n",
    "print(f\"k-Nearest Neighbors Average Test Accuracy: {np.mean(knn_accuracies_test):.4f} (+/- {np.std(knn_accuracies_test):.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
