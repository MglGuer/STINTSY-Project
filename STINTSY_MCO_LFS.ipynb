{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1. Introduction ##\n",
    "\n",
    "In this notebook, the dataset to be processed is the Labor Force Survey conducted April 2016 and retrieved through Philippine Statistics Authority database. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (6.0, 6.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# autoreload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Importing LFS PUF April 2016.CSV</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "try:\n",
    "    lfs_data = pd.read_csv(\"LFS PUF April 2016.CSV\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: CSV file not found. Please make sure the file exists in the correct directory or provide the correct path.\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Information, Pre-Processing, and Cleaning</h1>\n",
    "\n",
    "Let's get an overview of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Of interest to us, there are:\n",
    "<ul><li>1 contains float values, </li>\n",
    "<li>14 contain integer values, and </li>\n",
    "<li><b>35 are object values</b>.</li></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check for duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs_data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No duplicates here, and therefore no cleaning need follow in this regard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset seems to contain null values in the form of whitespaces. Let's count those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_null = lfs_data.apply(lambda col: col.str.isspace().sum() if col.dtype == 'object' else 0)\n",
    "\n",
    "print(\"Number Empty Cells:\")\n",
    "print(has_null[has_null > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "And standardize, replacing these whitespace values with NaN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs_data.replace(r\"^\\s+$\", np.nan, regex=True, inplace=True)\n",
    "nan_counts_per_column = lfs_data.isna().sum()\n",
    "print(nan_counts_per_column[nan_counts_per_column > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Let's also apply the unique() function to our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs_data.apply(lambda x: x.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Considering our dataset has 18,000 entries, features with particularly low numbers stand out as questions that have clear, defined choices. Reviewing the [questionnaire](https://psada.psa.gov.ph/catalog/67/download/537), we find that certain questions ask the participant to specify beyond prespecified choices.\n",
    "\n",
    "This column possibly contains \"010,\" which is obviously not an integer. We ensure this column is a string, and check for values not specified in the questionnaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs_data['PUFC07_GRADE'] = lfs_data['PUFC07_GRADE'].astype(str)\n",
    "valid_codes = [\n",
    "    \"000\", \"010\",                                      # No Grade, Preschool\n",
    "    \"210\", \"220\", \"230\", \"240\", \"250\", \"260\", \"280\",  # Elementary\n",
    "    \"310\", \"320\", \"330\", \"340\", \"350\",                # High School\n",
    "    \"410\", \"420\",                                     # Post Secondary; If Graduate Specify\n",
    "    \"810\", \"820\", \"830\", \"840\",                       # College; If Graduate Specify\n",
    "    \"900\",                                            # Post Baccalaureate\n",
    "    \"nan\"\n",
    "]\n",
    "invalid_rows = lfs_data[~(lfs_data['PUFC07_GRADE'].isin(valid_codes))]\n",
    "\n",
    "unique_invalid_values = invalid_rows['PUFC07_GRADE'].unique()\n",
    "print(unique_invalid_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values 5XX 6XX are not detailed in the questionnaire. As it instructs the participant to specify whether they graduated from post secondary or college, we'll create a new data point to encapsulate these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs_data.loc[~lfs_data['PUFC07_GRADE'].isin(valid_codes), 'PUFC07_GRADE'] = '700'\n",
    "print(lfs_data['PUFC07_GRADE'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = lfs_data.corr()\n",
    "\n",
    "strong_correlations = []\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):  # This ensures we don't get duplicates\n",
    "        corr_value = corr_matrix.iloc[i, j]\n",
    "        if (0.5 < corr_value < 1) or (-1 < corr_value < -0.5):\n",
    "            strong_correlations.append((\n",
    "                corr_matrix.index[i], \n",
    "                corr_matrix.columns[j], \n",
    "                corr_value\n",
    "            ))\n",
    "\n",
    "strong_correlations.sort(key=lambda x: abs(x[2]), reverse=True)\n",
    "\n",
    "print(\"Strong correlations (|corr| > 0.5 and |corr| < 1):\")\n",
    "for var1, var2, corr in strong_correlations:\n",
    "    print(f\"{var1} â€” {var2}: {corr:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
